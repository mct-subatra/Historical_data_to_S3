{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Configure AWS credentials\n",
    "aws_access_key_id = 'AKIASVLCQ7HIOJKQZH7L'\n",
    "aws_secret_access_key = 'TG8jFfBSPieGRA9201B6E0Y2QtRVDXQMjH+UhN7+'\n",
    "#aws_region = 'your_region'\n",
    "\n",
    "# Create an S3 client\n",
    "#s3 = boto3.client('s3', region_name=aws_region, aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "s3 = boto3.client('s3',aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "\n",
    "# Specify the local folder containing CSV files\n",
    "local_folder = 'C:/Users/dell-user/MCTProject/'\n",
    "\n",
    "# Specify the S3 bucket and prefix (folder) where you want to upload the files\n",
    "s3_bucket = 'bucketnew101'\n",
    "#s3_prefix = 'bucketcsvfile/' - specify the folder you want to store ins3 bucket\n",
    "\n",
    "# Loop through the CSV files in the local folder and upload them to S3\n",
    "csv_files = []\n",
    "for filename in os.listdir(local_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        local_file_path = filename\n",
    "        s3_object_key = local_file_path # s3_object_key = s3_prefix+local_file_path(folder+file is stored)\n",
    "        s3.upload_file(local_file_path, s3_bucket, s3_object_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
